# Orquix - Moderador de IA v2.0 Implementation

Plataforma completa de orquestaci√≥n de m√∫ltiples IAs con interfaz responsive y deployment en producci√≥n.

## Completed Tasks

- [x] Configuraci√≥n inicial del proyecto
- [x] Estructura backend FastAPI con endpoints principales
- [x] Implementaci√≥n del sistema de autenticaci√≥n mock
- [x] Base de datos PostgreSQL con esquemas principales
- [x] Integraci√≥n con m√∫ltiples proveedores de IA (OpenAI, Anthropic, Groq, Together)
- [x] Sistema de Context Manager acumulativo
- [x] Moderador v2.0 con s√≠ntesis inteligente
- [x] Frontend React con Zustand store
- [x] Componentes UI principales (sidebars, chat, modales)
- [x] Sistema de notificaciones toast
- [x] M√©tricas y monitoreo de IA providers
- [x] Deployment backend en Render (Web Service)
- [x] Configuraci√≥n CORS para producci√≥n
- [x] **Interfaz responsive completa**
- [x] **Navegaci√≥n m√≥vil con tabs**
- [x] **Layout adaptativo (m√≥vil/tablet/desktop)**
- [x] **Deployment frontend en Render (Static Site)**
- [x] **Correcci√≥n de problemas de layout m√≥vil**
- [x] **PreAnalyst completamente implementado e integrado**

## In Progress Tasks

- [ ] Testing de integraci√≥n completa del FollowUpInterpreter
- [ ] Optimizaci√≥n de rendimiento en m√≥viles
- [ ] Testing en diferentes navegadores y dispositivos
- [ ] Documentaci√≥n de usuario final

## Future Tasks

### High Priority
- [ ] **Tarea 1.3: Continuidad Conversacional Post-S√≠ntesis** - Sistema de follow-up conversacional para mantener el hilo de la investigaci√≥n
  - [x] **An√°lisis de Tipo de Consulta**
    - [x] Crear servicio `FollowUpInterpreter` para detectar si una consulta es nueva o continuaci√≥n
    - [x] Implementar detecci√≥n de referencias anaf√≥ricas ("Y si vamos con ni√±os", "mejora eso", "dame m√°s detalles")
    - [x] Integrar an√°lisis con PreAnalyst para determinar contexto necesario
    - [x] Desarrollar criterios para identificar cambio de tema vs. ampliaci√≥n
  - [x] **Recuperaci√≥n de Memoria Activa**
    - [x] Implementar funci√≥n `get_recent_interaction_context()` en `context_manager.py`
    - [x] Configurar recuperaci√≥n autom√°tica de √∫ltima s√≠ntesis del moderador
    - [x] Extraer prompts refinados y respuestas de IAs relevantes de la interacci√≥n previa
    - [x] Implementar l√≠mites de tokens/caracteres para contexto hist√≥rico
  - [x] **Enriquecimiento Contextual Inteligente**
    - [x] Desarrollar funci√≥n `enrich_prompt_with_history()` para combinar nueva consulta con historial
    - [x] Implementar template de prompt que preserva informaci√≥n previa relevante
    - [x] Evitar repetici√≥n de informaci√≥n ya proporcionada en s√≠ntesis anterior
    - [x] Mantener coherencia sem√°ntica entre consultas relacionadas
  - [x] **Integraci√≥n con Flujo Principal**
    - [x] Modificar endpoint `/projects/{project_id}/query` para incluir an√°lisis de continuidad
    - [x] Actualizar `AI Orchestrator` para usar contexto enriquecido autom√°ticamente
    - [x] Asegurar que el `AI Moderator` considere el hilo conversacional en nuevas s√≠ntesis
    - [x] Implementar logging espec√≠fico para tracking de continuidad conversacional
  - [ ] **Frontend - Indicadores de Continuidad**
    - [x] Crear componente visual para mostrar cuando se usa contexto previo
    - [x] Implementar "breadcrumb" conversacional en la interfaz de chat
    - [x] Agregar opci√≥n para usuario de "empezar nueva consulta" vs "continuar conversaci√≥n"
    - [x] Mostrar preview del contexto que se est√° utilizando de conversaciones anteriores
    - [x] **Dashboard conversacional detallado con m√©tricas y estado en tiempo real**
- [ ] **Tarea 1.4: Historial Conversacional Corto** - Incorporaci√≥n de memoria conversacional para referencias impl√≠citas
- [x] **Tarea 1.5: PreAnalystService - Interpretaci√≥n previa de consultas** - An√°lisis e interpretaci√≥n de la intenci√≥n del usuario antes de orquestar IAs
  - [x] Implementar clase `PreAnalysisResult` con campos requeridos
  - [x] Crear servicio `PreAnalystService` en `app/services/pre_analyst.py`
  - [x] Integrar GPT-3.5-Turbo para an√°lisis de intenciones
  - [x] Desarrollar endpoint `/analyze-prompt` para testing
  - [x] Integrar PreAnalyst con flujo principal de orquestaci√≥n
  - [x] Implementar flujo iterativo de clarificaci√≥n de preguntas
  - [x] **Integrar interfaz frontend con flujo de clarificaci√≥n**
    - [x] Crear servicio clarificationService.js
    - [x] Desarrollar componente ClarificationDialog.jsx
    - [x] Integrar estado de clarificaci√≥n en useAppStore.js
    - [x] Modificar CenterColumn.jsx para mostrar flujo de clarificaci√≥n
    - [x] A√±adir indicadores visuales para PreAnalyst
- [ ] Implementaci√≥n de speech-to-text en m√≥vil
- [ ] Optimizaci√≥n de Context Manager con historial reciente

### Medium Priority  
- [ ] Gestos t√°ctiles avanzados (swipe, pinch)
- [ ] Modo offline/PWA
- [ ] Push notifications
- [ ] Compartir conversaciones
- [ ] Exportar a PDF
- [ ] Themes/modo oscuro

### Low Priority
- [ ] Anal√≠ticas de uso
- [ ] Integraci√≥n con m√°s proveedores de IA
- [ ] Sistema de plugins/extensiones

## Implementation Plan

### Arquitectura Responsive

La aplicaci√≥n utiliza un dise√±o **mobile-first** con breakpoints espec√≠ficos:

- **Mobile (< 768px)**: Navegaci√≥n por tabs, layout de columna √∫nica
- **Tablet (768px - 1024px)**: Layout h√≠brido con sidebars colapsables  
- **Desktop (> 1024px)**: Layout de 3 columnas completo

### Tecnolog√≠as Utilizadas

**Backend:**
- FastAPI + PostgreSQL
- M√∫ltiples proveedores de IA
- Sistema de Context Manager
- Deployment: Render Web Service

**Frontend:**
- React + Vite + Tailwind CSS
- Zustand para state management
- Lucide React iconos
- Deployment: Render Static Site

### URLs de Producci√≥n

- **Backend**: `https://orquix-backend.onrender.com`
- **Frontend**: `https://orquix-frontend.onrender.com`

## Pr√≥xima Funcionalidad Prioritaria

### üß† Tarea 1.5: PreAnalystService - Interpretaci√≥n previa de consultas

**Problema**: Los usuarios env√≠an preguntas vagas, incompletas o ambiguas (ej: "necesito ayuda con el presupuesto de mi viaje"). Estas consultas requieren clarificaci√≥n antes de ser enviadas a las IAs orquestadas, generando respuestas gen√©ricas o irrelevantes.

**Soluci√≥n**: Implementar un servicio previo que analice la intenci√≥n del usuario, identifique informaci√≥n faltante y genere preguntas de clarificaci√≥n iterativas.

#### Flujo de Conversaci√≥n Ejemplo

1. **Usuario**: "necesito ayuda con el presupuesto de mi viaje"
2. **PreAnalyst**: Interpreta intenci√≥n + genera preguntas clarificadoras
3. **Usuario**: Responde "Es para Medell√≠n, 4 d√≠as, tengo $800 d√≥lares"  
4. **PreAnalyst**: Genera `refined_prompt_candidate` refinado
5. **Sistema**: Env√≠a prompt refinado al flujo normal de orquestaci√≥n

#### Implementaci√≥n T√©cnica

1. **Modelo de Datos**:
   ```python
   class PreAnalysisResult(BaseModel):
       interpreted_intent: str
       clarification_questions: List[str]
       refined_prompt_candidate: Optional[str]
   ```

2. **Servicio Principal**:
   ```python
   # app/services/pre_analyst.py
   async def analyze_prompt(user_prompt_text: str) -> PreAnalysisResult
   ```

3. **Integraci√≥n con OpenAI**:
   - Modelo: `gpt-3.5-turbo-1106` (econ√≥mico)
   - Temperature: 0.3 (consistencia)
   - Sistema prompt espec√≠fico para an√°lisis de intenciones

4. **Endpoint de Testing**:
   ```python
   # app/routers/pre_analyst.py
   @router.post("/analyze-prompt")
   async def analyze_user_prompt(...)
   ```

#### Archivos a Crear/Modificar

- `backend/app/services/pre_analyst.py` - ‚úÖ Servicio principal
- `backend/app/api/v1/endpoints/pre_analyst.py` - ‚úÖ Endpoint REST
- `backend/app/models/pre_analysis.py` - ‚úÖ Modelos Pydantic
- `backend/app/main.py` - ‚úÖ Integraci√≥n del router
- `backend/app/api/v1/endpoints/projects.py` - ‚úÖ Integraci√≥n con flujo principal
- `backend/app/services/clarification_manager.py` - ‚úÖ **Gesti√≥n de sesiones iterativas**
- `backend/app/api/v1/endpoints/pre_analyst.py` - ‚úÖ **Endpoints de clarificaci√≥n**

#### Beneficios

- ‚úÖ Mejora calidad de respuestas mediante clarificaci√≥n previa
- ‚úÖ Reduce tokens consumidos en orquestaci√≥n principal
- ‚úÖ Habilita manejo de referencias impl√≠citas futuras
- ‚úÖ Compatible con arquitectura actual
- ‚úÖ Costo-efectivo (modelo econ√≥mico GPT-3.5)

### üß† Tarea 1.4: Historial Conversacional Corto

**Problema**: Los usuarios utilizan referencias impl√≠citas en conversaciones multi-turno como "Dame los √∫ltimos 4", "Mejora eso", "Lo que me diste antes", etc. Estas frases carecen de contenido sem√°ntico suficiente para la b√∫squeda vectorial.

**Soluci√≥n**: Incorporar historial conversacional reciente para enriquecer el contexto antes de procesar nuevas consultas.

#### Implementaci√≥n T√©cnica

1. **Recuperaci√≥n de Historial**:
   ```sql
   SELECT user_prompt_text, moderated_synthesis
   FROM interaction_events
   WHERE project_id = ? AND user_id = ?
   ORDER BY created_at DESC
   LIMIT 3
   ```

2. **Enriquecimiento de Prompt**:
   ```python
   enriched_prompt = f"""
   Historial reciente:
   {historial_formateado}
   ---
   Nueva pregunta: {user_prompt}
   """
   ```

3. **Integraci√≥n con Context Manager**:
   - Usar `enriched_prompt` para b√∫squeda vectorial en `pgvector`
   - Pasar contexto enriquecido a las IAs orquestadas
   - Mantener coherencia en la s√≠ntesis del Moderador

#### Archivos a Modificar

- `backend/app/services/context_manager.py` - L√≥gica de enriquecimiento
- `backend/app/services/query_service.py` - Integraci√≥n con orquestaci√≥n
- `backend/app/routers/ai_orchestrator.py` - Endpoint actualizado

#### Beneficios

- ‚úÖ Mejora comprensi√≥n de preguntas anaf√≥ricas
- ‚úÖ Compatible con arquitectura actual (usa `interaction_events`)
- ‚úÖ Escalable (configurable por cantidad de eventos o tokens)
- ‚úÖ No requiere cambios de esquema de BD

### üîÑ Tarea 1.3: Continuidad Conversacional Post-S√≠ntesis

**Problema**: Orquix actualmente funciona como un sistema de "pregunta-respuesta √∫nica", pero debe comportarse como un asistente inteligente que acompa√±a al usuario durante una investigaci√≥n iterativa. Los usuarios esperan poder hacer seguimiento como "¬øY si vamos con ni√±os?" despu√©s de una consulta sobre viajes.

**Soluci√≥n**: Implementar un sistema de continuidad conversacional que detecte autom√°ticamente cuando una nueva consulta es una ampliaci√≥n de la anterior y use la s√≠ntesis previa como memoria activa.

#### Flujo de Conversaci√≥n Ejemplo

1. **Usuario inicial**: "Necesito ayuda para planear un viaje de 5 d√≠as a Cuba con mi esposa"
2. **Sistema**: [PreAnalyst + Orquestaci√≥n + S√≠ntesis] ‚Üí "Aqu√≠ est√°n las mejores opciones para un viaje de 5 d√≠as en Cuba..."
3. **Usuario follow-up**: "¬øY si fu√©ramos con ni√±os?"
4. **Sistema**: [Detecta continuidad + Enriquece contexto] ‚Üí Nuevo prompt: "Considerando el viaje a Cuba de 5 d√≠as que ya planificamos, c√≥mo adaptarlo para ir con ni√±os"
5. **Sistema**: [Orquestaci√≥n enriquecida + S√≠ntesis contextual]

#### Implementaci√≥n T√©cnica

1. **Servicio FollowUpInterpreter**:
   ```python
   class FollowUpInterpreter:
       async def analyze_query_continuity(
           user_prompt: str, 
           project_id: UUID, 
           user_id: UUID
       ) -> ContinuityAnalysis
   ```

2. **Modelo de Datos**:
   ```python
   class ContinuityAnalysis(BaseModel):
       is_continuation: bool
       reference_type: str  # "anaphoric", "topic_expansion", "clarification", "new_topic"
       confidence_score: float
       previous_interaction_id: Optional[UUID]
       contextual_keywords: List[str]
   ```

3. **Recuperaci√≥n de Memoria Activa**:
   ```python
   async def get_recent_interaction_context(
       project_id: UUID, 
       user_id: UUID, 
       max_interactions: int = 1
   ) -> InteractionContext
   ```

4. **Enriquecimiento Contextual**:
   ```python
   def enrich_prompt_with_history(
       current_prompt: str,
       previous_synthesis: str,
       previous_refined_prompt: str
   ) -> str:
       return f"""
       CONTEXTO PREVIO (para referencia):
       Consulta anterior: {previous_refined_prompt}
       S√≠ntesis proporcionada: {previous_synthesis[:500]}...
       
       NUEVA CONSULTA (ampl√≠a o modifica lo anterior):
       {current_prompt}
       
       INSTRUCCI√ìN: Responde considerando el contexto previo pero enf√≥cate en la nueva consulta.
       """
   ```

#### Archivos a Crear/Modificar

**Backend - Nuevos Servicios**:
- `backend/app/services/followup_interpreter.py` - Detecta tipo de continuidad
- `backend/app/models/continuity.py` - Modelos de datos para continuidad
- `backend/app/services/conversation_memory.py` - Gesti√≥n de memoria conversacional

**Backend - Modificaciones**:
- `backend/app/services/context_manager.py` - Agregar funciones de recuperaci√≥n de historial
- `backend/app/api/v1/endpoints/projects.py` - Integrar an√°lisis de continuidad en `/query`
- `backend/app/services/ai_orchestrator.py` - Usar contexto enriquecido
- `backend/app/services/ai_moderator.py` - S√≠ntesis consciente del hilo conversacional

**Frontend - Nuevos Componentes**:
- `frontend/src/components/chat/ContinuityIndicator.jsx` - Muestra cuando se usa contexto previo
- `frontend/src/components/chat/ConversationBreadcrumb.jsx` - Rastro visual de la conversaci√≥n
- `frontend/src/components/chat/ContextPreview.jsx` - Preview del contexto utilizado

**Frontend - Modificaciones**:
- `frontend/src/store/useAppStore.js` - Estado para tracking de continuidad
- `frontend/src/components/layout/CenterColumn.jsx` - Integrar indicadores visuales
- `frontend/src/services/api.js` - Endpoints para gesti√≥n de continuidad

#### Criterios de Detecci√≥n de Continuidad

**Referencias Anaf√≥ricas** (is_continuation = true):
- Pronombres: "eso", "esto", "lo anterior", "lo que dijiste"
- Temporal: "despu√©s de eso", "luego", "tambi√©n"
- Condicional: "¬øy si...?", "pero qu√© tal si..."
- Expansi√≥n: "adem√°s", "tambi√©n considera", "otra opci√≥n"

**Cambio de Tema** (is_continuation = false):
- Palabras clave completamente diferentes
- Cambio radical de dominio (ej: viajes ‚Üí programaci√≥n)
- Indicadores expl√≠citos: "ahora quiero", "nueva consulta", "cambiando de tema"

#### Beneficios Esperados

- ‚úÖ Experiencia conversacional natural e intuitiva
- ‚úÖ Reduce fricci√≥n para el usuario en consultas iterativas
- ‚úÖ Maximiza reutilizaci√≥n del conocimiento ya generado
- ‚úÖ Convierte Orquix en un verdadero asistente de investigaci√≥n
- ‚úÖ Compatible con la arquitectura actual de `interaction_events`
- ‚úÖ Escalable y configurable (l√≠mites de memoria, tokens, etc.)

## Relevant Files

### Backend Core ‚úÖ
- `backend/app/main.py` - FastAPI app principal con CORS
- `backend/app/routers/ai_orchestrator.py` - Endpoints de orquestaci√≥n  
- `backend/app/routers/projects.py` - Gesti√≥n de proyectos
- `backend/app/routers/moderator.py` - Moderador v2.0
- `backend/app/services/pre_analyst.py` - ‚úÖ **PreAnalystService**
- `backend/app/api/v1/endpoints/pre_analyst.py` - ‚úÖ **Endpoints PreAnalyst**
- `backend/app/models/pre_analysis.py` - ‚úÖ **Modelos PreAnalysis**
- `backend/app/services/followup_interpreter.py` - ‚úÖ **Detecci√≥n de continuidad conversacional**
- `backend/app/services/context_manager.py` - ‚úÖ **Funci√≥n get_recent_interaction_context() a√±adida**
- `backend/app/api/v1/endpoints/projects.py` - ‚úÖ **Integrado con an√°lisis de continuidad**
- `backend/tests/test_followup_interpreter.py` - ‚úÖ **Pruebas completas del FollowUpInterpreter**
- `backend/app/database/database.py` - Configuraci√≥n PostgreSQL
- `backend/app/database/models.py` - Modelos SQLAlchemy

### Frontend Responsive ‚úÖ
- `frontend/src/App.jsx` - Layout responsive principal
- `frontend/src/components/layout/MobileNavigation.jsx` - Navegaci√≥n m√≥vil
- `frontend/src/components/layout/LeftSidebar.jsx` - Sidebar proyectos (responsive)
- `frontend/src/components/layout/CenterColumn.jsx` - Chat principal (responsive)
- `frontend/src/components/layout/RightSidebar.jsx` - Agentes IA (responsive)
- `frontend/src/components/chat/ContinuityIndicator.jsx` - ‚è≥ **Indicador de contexto previo**
- `frontend/src/components/chat/ConversationBreadcrumb.jsx` - ‚è≥ **Rastro conversacional**
- `frontend/src/components/chat/ContextPreview.jsx` - ‚è≥ **Preview de contexto utilizado**
- `frontend/src/index.css` - Estilos responsive y m√≥viles

### Configuration ‚úÖ
- `render.yaml` - Configuraci√≥n fullstack deployment
- `frontend/vite.config.js` - Build optimizado para producci√≥n
- `frontend/src/config.js` - URLs din√°micas dev/prod
- `frontend/public/_redirects` - SPA routing para Render
- `frontend/index.html` - Meta tags optimizados para m√≥vil

### Documentation ‚úÖ
- `DEPLOYMENT.md` - Gu√≠a completa de deployment
- `README.md` - Arquitectura y URLs de producci√≥n
- `docs/frontend_deployment_render.md` - Opci√≥n B implementada

## Testing Checklist

### Mobile Testing (< 768px)
- [ ] iPhone SE (375x667) - Navegaci√≥n tabs
- [ ] iPhone 12 Pro (390x844) - Layout responsive  
- [ ] Galaxy Fold (280x653) - Pantallas muy peque√±as
- [ ] Orientaci√≥n portrait/landscape
- [ ] Touch gestures y scrolling

### Tablet Testing (768px - 1024px)  
- [ ] iPad (768x1024) - Layout h√≠brido
- [ ] Surface Pro (912x1368) - Windows tablet

### Desktop Testing (> 1024px)
- [ ] 1920x1080 - Layout 3 columnas
- [ ] 4K displays - Escalado
- [ ] Diferentes browsers (Chrome, Firefox, Safari, Edge)

## Performance Metrics

- [ ] Lighthouse mobile score > 90
- [ ] First Contentful Paint < 1.5s
- [ ] Time to Interactive < 3s
- [ ] Bundle size analysis
- [ ] Core Web Vitals optimization

## Deployment Status

- ‚úÖ **Backend**: Deployado y funcional en Render
- ‚úÖ **Frontend**: Deployado con Static Site en Render  
- ‚úÖ **Database**: PostgreSQL en Render
- ‚úÖ **CORS**: Configurado para producci√≥n
- ‚úÖ **SSL**: Certificados autom√°ticos
- ‚úÖ **CDN**: Global con Render Static Site
