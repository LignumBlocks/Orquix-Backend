import pytest
from uuid import UUID, uuid4
from datetime import datetime, timezone
from app.services.pre_analyst import pre_analyst_service
from app.services.clarification_manager import clarification_manager
from app.services.prompt_templates import PromptTemplateManager
from app.schemas.ai_response import AIProviderEnum
from app.models.pre_analysis import (
    PreAnalysisResult,
    ClarificationRequest,
    ClarificationResponse
)

# Datos de ejemplo para las pruebas
CONTEXT_EXAMPLE = """Durante la √∫ltima d√©cada, la penetraci√≥n de soluciones de IA conversacional y automatizaci√≥n de procesos rob√≥ticos (RPA) en los call-centers latinoamericanos ha ido en aumento, impulsada por la r√°pida expansi√≥n del e-commerce regional y la creciente demanda de atenci√≥n multiling√ºe 24/7. Diversos estudios‚Äîentre ellos el informe "The Service Automation Index" del MIT (2024) y el reporte de la OECD "Automation and Emerging Markets" (2023)‚Äîcoinciden en que el sector servicios ser√° uno de los m√°s transformados antes de 2030. Mientras los an√°lisis optimistas destacan mejoras en productividad, creaci√≥n de nuevos roles especializados y oportunidades de upskilling, las proyecciones pesimistas advierten de una posible sustituci√≥n del 20 % a 40 % de los agentes humanos, con riesgos de precarizaci√≥n laboral y profundizaci√≥n de la desigualdad salarial en la regi√≥n."""

# Simulamos una interacci√≥n previa para tener contexto acumulado
PREVIOUS_INTERACTION = {
    'timestamp': '2024-03-20T15:30:00Z',
    'user_prompt': '¬øQu√© son los call centers?',
    'refined_prompt': 'Explica qu√© son los call centers, su funci√≥n principal y su importancia en el servicio al cliente moderno.',
    'synthesis': """Los call centers son centros de atenci√≥n telef√≥nica que funcionan como punto de contacto entre empresas y clientes. Sus funciones principales incluyen:
1. Atenci√≥n al cliente y soporte t√©cnico
2. Ventas y telemarketing
3. Gesti√≥n de reclamos y consultas
4. Servicios post-venta

En el contexto actual, los call centers han evolucionado para incluir m√∫ltiples canales de comunicaci√≥n (omnicanalidad) y tecnolog√≠as avanzadas como IA y automatizaci√≥n."""
}

VAGUE_QUERY = "¬øqu√© opinas sobre la automatizaci√≥n en call centers?"

@pytest.mark.asyncio
async def test_force_proceed_flow():
    """
    Prueba el flujo completo de force_proceed con contexto acumulado:
    1. PreAnalyst analiza una pregunta vaga sobre automatizaci√≥n
    2. Sugiere clarificaciones pero genera refined_prompt usando el contexto
    3. Usuario fuerza avance sin responder preguntas
    4. Sistema usa el refined_prompt con TODO el contexto para las IAs
    """
    print("\n=== Test de Force Proceed con Clarificaciones Opt-in y Contexto Acumulado ===")
    
    # Setup
    project_id = uuid4()
    user_id = uuid4()
    prompt_manager = PromptTemplateManager()
    
    print("\nüìù Historial de Interacci√≥n:")
    print(f"Pregunta anterior: {PREVIOUS_INTERACTION['user_prompt']}")
    print(f"S√≠ntesis previa: {PREVIOUS_INTERACTION['synthesis'][:200]}...")
    
    print("\n‚ùì Nueva pregunta del usuario:", VAGUE_QUERY)
    print("\nüìö Contexto del proyecto:", CONTEXT_EXAMPLE[:100] + "...")
    
    # Paso 1: An√°lisis inicial con PreAnalyst
    print("\n1Ô∏è‚É£ An√°lisis PreAnalyst")
    analysis_result = await pre_analyst_service.analyze_prompt(VAGUE_QUERY)
    
    # Verificar que tenemos preguntas de clarificaci√≥n Y refined_prompt
    assert len(analysis_result.clarification_questions) > 0, "Deber√≠a sugerir clarificaciones para pregunta vaga"
    assert analysis_result.refined_prompt_candidate is not None, "Deber√≠a generar refined_prompt"
    
    print(f"üîç Intenci√≥n interpretada: {analysis_result.interpreted_intent}")
    print("\n‚ùì Preguntas sugeridas:")
    for q in analysis_result.clarification_questions:
        print(f"   ‚Ä¢ {q}")
    print(f"\nüìù Prompt refinado: {analysis_result.refined_prompt_candidate}")
    
    # Paso 2: Iniciar sesi√≥n de clarificaci√≥n
    print("\n2Ô∏è‚É£ Iniciando sesi√≥n de clarificaci√≥n")
    clarification_response = await clarification_manager.start_clarification_session(
        project_id=project_id,
        user_id=user_id,
        initial_prompt=VAGUE_QUERY
    )
    
    print(f"Session ID: {clarification_response.session_id}")
    print("Estado inicial:", "Completo ‚úÖ" if clarification_response.is_complete else "Esperando clarificaci√≥n ‚è≥")
    
    # Paso 3: Forzar avance sin responder preguntas
    print("\n3Ô∏è‚É£ Usuario elige 'Continuar de todos modos'")
    force_request = ClarificationRequest(
        session_id=clarification_response.session_id,
        project_id=project_id,
        user_response="",
        force_proceed=True
    )
    
    # Simular force_proceed
    forced_response = clarification_manager.force_proceed_session(force_request.session_id)
    assert forced_response is not None, "Deber√≠a obtener respuesta al forzar"
    assert forced_response.is_complete, "Sesi√≥n deber√≠a estar completa"
    assert not forced_response.next_questions, "No deber√≠a haber m√°s preguntas"
    
    print("‚úÖ Sesi√≥n marcada como completa")
    print("üö´ Preguntas de clarificaci√≥n: omitidas")
    
    # Paso 4: Preparar prompts para cada IA usando el contexto acumulado
    print("\n4Ô∏è‚É£ Preparando prompts completos para IAs (con todo el contexto)")
    
    # Lista de chunks de contexto en orden de relevancia
    context_chunks = [
        # Contexto del proyecto actual
        {
            'source_type': 'project_context',
            'similarity_score': 0.95,
            'content_text': CONTEXT_EXAMPLE
        },
        # Interacci√≥n previa relevante
        {
            'source_type': 'interaction_history',
            'similarity_score': 0.85,
            'content_text': f"""[Interacci√≥n previa - {PREVIOUS_INTERACTION['timestamp']}]
Pregunta: {PREVIOUS_INTERACTION['refined_prompt']}
S√≠ntesis: {PREVIOUS_INTERACTION['synthesis']}"""
        }
    ]
    
    # Mostrar prompts completos para cada proveedor
    for provider in [AIProviderEnum.OPENAI, AIProviderEnum.ANTHROPIC]:
        print(f"\n\nü§ñ PROMPT COMPLETO PARA {provider}")
        print("=" * 80)
        
        # Formatear contexto seg√∫n el template del proveedor
        context_formatted = prompt_manager.format_context_for_provider(
            provider=provider,
            context_chunks=context_chunks
        )
        
        # Construir prompt completo
        prompt_data = prompt_manager.build_prompt_for_provider(
            provider=provider,
            user_question=analysis_result.refined_prompt_candidate,
            context_text=context_formatted,
            additional_vars={
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'project_name': 'Test Project',
                'user_name': 'Test User'
            }
        )
        
        print("\nüìã SYSTEM MESSAGE:")
        print("-" * 40)
        print(prompt_data['system_message'])
        
        print("\nüìö CONTEXTO FORMATEADO:")
        print("-" * 40)
        print(context_formatted)
        
        print("\nüí¨ USER MESSAGE:")
        print("-" * 40)
        print(prompt_data['user_message']) 