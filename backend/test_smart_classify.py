#!/usr/bin/env python3
"""
Script de prueba para demostrar el funcionamiento del clasificador multiling√ºe
del ContextBuilderService refactorizado.
"""

import asyncio
import json
import logging
from typing import Tuple
import openai
import os
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Funciones helper (copias de las implementadas en context_builder.py)
async def classify_message_llm(
    client: openai.AsyncOpenAI,
    user_message: str,
    model: str = "gpt-3.5-turbo"
) -> Tuple[str, float]:
    """
    Clasifica un mensaje usando LLM de forma agn√≥stica al idioma.
    """
    prompt = (
        "You are a language-agnostic classifier. "
        "Return ONLY valid JSON with keys: "
        "message_type ('question' or 'information') and confidence (0-1). "
        f"Text: ¬´{user_message.strip()}¬ª"
    )
    try:
        chat = await client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=50,
            response_format={"type": "json_object"}
        )
        data = json.loads(chat.choices[0].message.content)
        if data["message_type"] in ("question", "information"):
            return data["message_type"], float(data["confidence"])
    except Exception as e:
        logger.debug(f"LLM classify failed ‚Üí fallback: {e}")
    return _fallback_heuristic(user_message)

def _fallback_heuristic(msg: str) -> Tuple[str, float]:
    """
    Heur√≠stica universal de fallback para clasificaci√≥n.
    """
    text = msg.strip()
    if text.endswith("?") or (text.count("?") == 1 and len(text) < 80):
        return "question", 0.6
    if len(text.split()) > 15:
        return "information", 0.6
    return "question", 0.5

class SmartClassifyTester:
    """Tester para el clasificador multiling√ºe."""
    
    def __init__(self):
        self.client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-3.5-turbo"
    
    async def _smart_classify(self, user_message: str) -> Tuple[str, float]:
        """M√©todo de clasificaci√≥n inteligente."""
        return await classify_message_llm(self.client, user_message, self.model)
    
    async def test_multilingual_classification(self):
        """Prueba la clasificaci√≥n en m√∫ltiples idiomas."""
        
        # Casos de prueba multiling√ºes
        test_cases = [
            # Espa√±ol - Preguntas
            ("¬øC√≥mo puedo mejorar mi negocio?", "question"),
            ("¬øQu√© estrategias me recomiendas?", "question"),
            ("Necesito ayuda con mi startup", "question"),
            
            # Espa√±ol - Informaci√≥n
            ("Tengo una empresa de tecnolog√≠a que desarrolla aplicaciones m√≥viles", "information"),
            ("Mi startup est√° en el sector fintech y operamos desde hace 2 a√±os", "information"),
            ("Somos una empresa B2B que vende software a grandes corporaciones", "information"),
            
            # Ingl√©s - Preguntas
            ("How can I improve my business?", "question"),
            ("What strategies do you recommend?", "question"),
            ("I need help with my startup", "question"),
            
            # Ingl√©s - Informaci√≥n
            ("I have a technology company that develops mobile applications", "information"),
            ("My startup is in the fintech sector and we've been operating for 2 years", "information"),
            ("We are a B2B company that sells software to large corporations", "information"),
            
            # Portugu√©s - Preguntas
            ("Como posso melhorar meu neg√≥cio?", "question"),
            ("Que estrat√©gias voc√™ recomenda?", "question"),
            ("Preciso de ajuda com minha startup", "question"),
            
            # Portugu√©s - Informaci√≥n
            ("Tenho uma empresa de tecnologia que desenvolve aplicativos m√≥veis", "information"),
            ("Minha startup est√° no setor fintech e operamos h√° 2 anos", "information"),
            
            # Franc√©s - Preguntas
            ("Comment puis-je am√©liorer mon entreprise?", "question"),
            ("Quelles strat√©gies recommandez-vous?", "question"),
            
            # Franc√©s - Informaci√≥n
            ("J'ai une entreprise de technologie qui d√©veloppe des applications mobiles", "information"),
            ("Ma startup est dans le secteur fintech et nous op√©rons depuis 2 ans", "information"),
            
            # Casos edge
            ("Hola", "question"),  # Mensaje muy corto
            ("?", "question"),  # Solo signo de interrogaci√≥n
            ("Esta es una descripci√≥n muy larga de mi empresa que se dedica a desarrollar software para el sector bancario, tenemos m√°s de 100 empleados y operamos en 5 pa√≠ses diferentes de Am√©rica Latina ofreciendo servicios de consultor√≠a y desarrollo de aplicaciones", "information"),  # Mensaje muy largo
        ]
        
        print("\nüöÄ PRUEBA DEL CLASIFICADOR MULTILING√úE")
        print("=" * 60)
        
        correct_predictions = 0
        total_tests = len(test_cases)
        
        for i, (message, expected_type) in enumerate(test_cases, 1):
            try:
                print(f"\nüìù Test {i:2d}: {message[:50]}{'...' if len(message) > 50 else ''}")
                
                # Clasificar con LLM
                predicted_type, confidence = await self._smart_classify(message)
                
                # Verificar predicci√≥n
                is_correct = predicted_type == expected_type
                if is_correct:
                    correct_predictions += 1
                
                # Mostrar resultado
                status = "‚úÖ CORRECTO" if is_correct else "‚ùå INCORRECTO"
                print(f"   Esperado: {expected_type:11} | Predicho: {predicted_type:11} | Confianza: {confidence:.2f} | {status}")
                
                # Mostrar fallback si la confianza es baja
                if confidence < 0.55:
                    print(f"   ‚ö†Ô∏è  Confianza baja ({confidence:.2f}) - Se usar√≠a mensaje de aclaraci√≥n")
                
            except Exception as e:
                print(f"   üî• ERROR: {e}")
                # Probar fallback heur√≠stico
                fallback_type, fallback_conf = _fallback_heuristic(message)
                print(f"   üîÑ Fallback: {fallback_type} (confianza: {fallback_conf:.2f})")
        
        # Mostrar estad√≠sticas finales
        accuracy = (correct_predictions / total_tests) * 100
        print(f"\nüìä RESULTADOS FINALES")
        print("=" * 60)
        print(f"Total de pruebas: {total_tests}")
        print(f"Predicciones correctas: {correct_predictions}")
        print(f"Precisi√≥n: {accuracy:.1f}%")
        
        if accuracy >= 80:
            print("üéâ ¬°Excelente! El clasificador funciona muy bien")
        elif accuracy >= 70:
            print("üëç Buen rendimiento del clasificador")
        else:
            print("‚ö†Ô∏è  El clasificador necesita mejoras")
    
    async def test_confidence_handling(self):
        """Prueba el manejo de casos de baja confianza."""
        
        print("\nüéØ PRUEBA DE MANEJO DE CONFIANZA")
        print("=" * 60)
        
        # Casos ambiguos que deber√≠an dar baja confianza
        ambiguous_cases = [
            "OK",
            "S√≠",
            "Entiendo",
            "Tal vez",
            "No s√©",
            "...",
            "Mmm",
            "Bien",
        ]
        
        for message in ambiguous_cases:
            try:
                predicted_type, confidence = await self._smart_classify(message)
                print(f"üìù '{message:15}' ‚Üí {predicted_type:11} (confianza: {confidence:.2f})")
                
                if confidence < 0.55:
                    print(f"   üí¨ Se activar√≠a: 'No estoy seguro de si eso es una pregunta o informaci√≥n. ¬øPodr√≠as aclararlo?'")
                
            except Exception as e:
                print(f"üî• Error con '{message}': {e}")
    
    async def run_all_tests(self):
        """Ejecuta todas las pruebas."""
        try:
            await self.test_multilingual_classification()
            await self.test_confidence_handling()
            
            print(f"\n‚ú® FUNCIONAMIENTO DEL SISTEMA")
            print("=" * 60)
            print("1. üß† LLM Multiling√ºe: Usa GPT-3.5 para clasificar en cualquier idioma")
            print("2. üîÑ Fallback Universal: Si falla el LLM, usa heur√≠stica simple")
            print("3. üéØ Control de Confianza: Si confianza < 0.55, pide aclaraci√≥n")
            print("4. üåç Agn√≥stico al idioma: Funciona en ES, EN, PT, FR, etc.")
            print("5. üõ°Ô∏è  Robusto: Nunca falla, siempre retorna una clasificaci√≥n")
            
        except Exception as e:
            print(f"üî• Error en las pruebas: {e}")

async def main():
    """Funci√≥n principal."""
    print("üöÄ INICIANDO PRUEBAS DEL CLASIFICADOR MULTILING√úE")
    print("=" * 60)
    
    # Verificar API key
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå Error: OPENAI_API_KEY no est√° configurada")
        print("Por favor, configura tu API key de OpenAI en el archivo .env")
        return
    
    tester = SmartClassifyTester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main()) 