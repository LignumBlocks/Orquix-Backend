# IncorporaciÃ³n de Historial Conversacional Corta en Orquix

## ğŸ¯ Problema

En interacciones multi-turno, los usuarios pueden usar frases con referencias implÃ­citas como:

> "Dame los Ãºltimos 4"

Estas frases **no tienen suficiente contenido semÃ¡ntico por sÃ­ solas** para ser interpretadas correctamente por un sistema que depende de bÃºsqueda vectorial (`pgvector`). El resultado: el sistema **no encuentra nada relevante**, porque no hay coincidencias directas con â€œlos Ãºltimos 4â€.

---

## âœ… SoluciÃ³n: Historial Conversacional Reciente

Antes de enviar una nueva pregunta a las IAs orquestadas, el sistema debe **reconstruir un bloque textual con las interacciones anteriores mÃ¡s recientes** (user + moderador).

### Ejemplo

SupÃ³n el historial reciente fue:

```
Usuario: Hazme un itinerario de 4 dÃ­as por Miami
Moderador: DÃ­a 1: ..., DÃ­a 2: ..., DÃ­a 3: ..., DÃ­a 4: ...
Usuario: Dame los Ãºltimos 4
```

En lugar de enviar solo:

```
Dame los Ãºltimos 4
```

Debemos enviar:

```
Historial reciente:
Usuario: Hazme un itinerario de 4 dÃ­as por Miami
Moderador: DÃ­a 1: ..., DÃ­a 2: ...
---

Nueva pregunta: Dame los Ãºltimos 4
```

Esto proporciona el contexto necesario para que tanto el **Gestor de Contexto** como las **IAs** puedan interpretar correctamente la intenciÃ³n.

---

## âš™ï¸ CÃ³mo se implementa

1. En el `ContextManager`, al recibir una nueva consulta:
2. Recuperar los Ãºltimos N `interaction_events` del mismo `project_id` y `user_id`:
   ```sql
   SELECT user_prompt_text, moderated_synthesis
   FROM interaction_events
   WHERE project_id = ? AND user_id = ?
   ORDER BY created_at DESC
   LIMIT 3
   ```

3. Formatear los resultados:
   ```
   Usuario: ...
   Moderador: ...
   ```

4. Concatenar el historial con el prompt actual:
   ```python
   enriched_prompt = historial + "\n---\nNueva pregunta: " + user_prompt
   ```

5. Este `enriched_prompt` se usa:
   - Para generar el embedding de bÃºsqueda en `pgvector`
   - Y/o se pasa directamente a las IAs

---

## ğŸ§  Ventajas

| Ventaja | Beneficio |
|--------|-----------|
| No requiere estructura nueva en la base de datos | Usa `interaction_events` |
| Compatible con el MVP actual | Se puede integrar de inmediato |
| Mejora comprensiÃ³n de preguntas anafÃ³ricas | â€œesoâ€, â€œlos 4 Ãºltimosâ€, â€œlo que me disteâ€ |
| Escalable | Puedes controlar cuÃ¡ntos eventos usar (por tokens, tiempo o cantidad) |

---

## ğŸ› ï¸ RecomendaciÃ³n de implementaciÃ³n

Agregar esta funcionalidad como parte de la **Tarea 1.3 (Context Block)** o crear una nueva:

> **Tarea 1.4: IncorporaciÃ³n de Memoria Conversacional Corta**

---

## ğŸ“Œ Notas

- Este historial no se guarda como contexto vectorial (no son chunks), sino como bloque textual dinÃ¡mico.
- Se recomienda usar `created_at DESC` para priorizar lo mÃ¡s reciente.
- Puedes controlar el tamaÃ±o mÃ¡ximo por cantidad o tokens.

