import pytest
import asyncio
from app.services.ai_orchestrator import AIOrchestrator, AIOrchestrationStrategy
from app.schemas.ai_response import AIRequest, AIProviderEnum, AIResponseStatus
from app.core.config import settings

async def test_orchestrator_initialization():
    """Prueba la inicializaciÃ³n del orquestador"""
    print("\nğŸ¤– Probando inicializaciÃ³n del orquestador...")
    
    orchestrator = AIOrchestrator()
    
    available_providers = orchestrator.get_available_providers()
    print(f"   ğŸ“‹ Proveedores disponibles: {available_providers}")
    
    assert isinstance(available_providers, list)
    
    # Verificar que al menos OpenAI estÃ© disponible (ya que tenemos la API key)
    if settings.OPENAI_API_KEY:
        assert AIProviderEnum.OPENAI in available_providers
        print("   âœ… OpenAI disponible")
    
    await orchestrator.close()
    return True

async def test_single_openai_request():
    """Prueba una solicitud simple a OpenAI"""
    print("\nğŸ¯ Probando solicitud individual a OpenAI...")
    
    orchestrator = AIOrchestrator()
    
    if AIProviderEnum.OPENAI not in orchestrator.get_available_providers():
        print("   âš ï¸ OpenAI no disponible, saltando prueba")
        return True
    
    request = AIRequest(
        prompt="Explica en una oraciÃ³n quÃ© es la inteligencia artificial.",
        max_tokens=50,
        temperature=0.7
    )
    
    response = await orchestrator.generate_single_response(
        request, 
        AIProviderEnum.OPENAI
    )
    
    print(f"   ğŸ¤– Proveedor: {response.ia_provider_name}")
    print(f"   ğŸ“Š Estado: {response.status}")
    print(f"   â±ï¸  Latencia: {response.latency_ms}ms")
    
    if response.status == AIResponseStatus.SUCCESS:
        print(f"   ğŸ’¬ Respuesta: {response.response_text}")
        print(f"   ğŸ“ˆ Uso: {response.usage_info}")
        assert response.response_text is not None
        assert len(response.response_text) > 0
    else:
        print(f"   âŒ Error: {response.error_message}")
    
    await orchestrator.close()
    return True

async def test_fallback_strategy():
    """Prueba la estrategia de fallback"""
    print("\nğŸ”„ Probando estrategia de fallback...")
    
    orchestrator = AIOrchestrator()
    
    available_providers = orchestrator.get_available_providers()
    if not available_providers:
        print("   âš ï¸ No hay proveedores disponibles, saltando prueba")
        return True
    
    request = AIRequest(
        prompt="Â¿CuÃ¡l es la capital de EspaÃ±a?",
        max_tokens=30,
        temperature=0.3
    )
    
    response = await orchestrator.orchestrate(
        request, 
        strategy=AIOrchestrationStrategy.FALLBACK
    )
    
    print(f"   ğŸ¤– Proveedor usado: {response.ia_provider_name}")
    print(f"   ğŸ“Š Estado: {response.status}")
    print(f"   â±ï¸  Latencia: {response.latency_ms}ms")
    
    if response.status == AIResponseStatus.SUCCESS:
        print(f"   ğŸ’¬ Respuesta: {response.response_text}")
        assert response.response_text is not None
    else:
        print(f"   âŒ Error: {response.error_message}")
    
    await orchestrator.close()
    return True

async def test_parallel_strategy():
    """Prueba la estrategia paralela (solo si hay mÃºltiples proveedores)"""
    print("\nâš¡ Probando estrategia paralela...")
    
    orchestrator = AIOrchestrator()
    
    available_providers = orchestrator.get_available_providers()
    if len(available_providers) < 1:
        print("   âš ï¸ Se necesita al menos un proveedor para esta prueba")
        return True
    
    request = AIRequest(
        prompt="Di 'Hola' en espaÃ±ol.",
        max_tokens=10,
        temperature=0.1
    )
    
    responses = await orchestrator.orchestrate(
        request, 
        strategy=AIOrchestrationStrategy.PARALLEL
    )
    
    print(f"   ğŸ“Š NÃºmero de respuestas: {len(responses)}")
    
    for i, response in enumerate(responses, 1):
        print(f"   ğŸ¤– Respuesta #{i}:")
        print(f"      â†’ Proveedor: {response.ia_provider_name}")
        print(f"      â†’ Estado: {response.status}")
        print(f"      â†’ Latencia: {response.latency_ms}ms")
        
        if response.status == AIResponseStatus.SUCCESS:
            print(f"      â†’ Texto: {response.response_text}")
        else:
            print(f"      â†’ Error: {response.error_message}")
    
    await orchestrator.close()
    return True

if __name__ == "__main__":
    async def run_all_tests():
        tests = [
            test_orchestrator_initialization(),
            test_single_openai_request(),
            test_fallback_strategy(),
            test_parallel_strategy()
        ]
        
        results = await asyncio.gather(*tests, return_exceptions=True)
        
        success_count = 0
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"âŒ Test {i+1} fallÃ³: {result}")
            elif result:
                success_count += 1
                print(f"âœ… Test {i+1} exitoso")
            else:
                print(f"âŒ Test {i+1} fallÃ³")
        
        print(f"\nğŸ¯ RESULTADO: {success_count}/{len(tests)} tests exitosos")
        return success_count == len(tests)
    
    result = asyncio.run(run_all_tests())
    if result:
        print("ğŸ‰ Todos los tests del orquestador pasaron!")
    else:
        print("ğŸ’¥ Algunos tests fallaron") 